# Pauline : fasterq-dump via Homebrew
# T√©l√©chargement des donn√©es en parall√®le pour diviser le temps par 6
import os
import subprocess
import glob
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed

SRA_IDS = [
    "SRR10379721", "SRR10379722", "SRR10379723",  # Persisters
    "SRR10379724", "SRR10379725", "SRR10379726"   # Controls
]
N_CPU = 4
N_PARALLEL = 3  # nombre de t√©l√©chargements simultan√©s (ajuste selon ta connexion)

# Cr√©er dossier data
os.makedirs("data", exist_ok=True)
os.chdir("data")

def download_sra(SRA_ID):
    print(f"‚û°Ô∏è  Downloading {SRA_ID} ...")
    try:
        subprocess.run([
            "fasterq-dump", "--threads", str(N_CPU), "--progress", SRA_ID
        ], check=True)
        print(f"‚úÖ {SRA_ID} done.")
        return SRA_ID
    except subprocess.CalledProcessError:
        print(f"‚ùå Error downloading {SRA_ID}")
        return None

# T√©l√©chargements parall√®les
print(f"üöÄ Starting parallel downloads ({N_PARALLEL} at a time)...")
with ThreadPoolExecutor(max_workers=N_PARALLEL) as executor:
    futures = {executor.submit(download_sra, sra): sra for sra in SRA_IDS}
    for future in as_completed(futures):
        sra = futures[future]
        if future.result() is None:
            print(f"‚ö†Ô∏è {sra} failed!")

# Compression
print("üóúÔ∏è  Compressing FASTQ files...")
subprocess.run("gzip *.fastq", shell=True, check=True)

# V√©rification
gz_files = glob.glob("*.fastq.gz")
print("\nVerification:")
if len(gz_files) == len(SRA_IDS):
    print(f"‚úÖ All {len(gz_files)} files downloaded and compressed successfully!")
else:
    missing = len(SRA_IDS) - len(gz_files)
    print(f"‚ö†Ô∏è Warning: {missing} file(s) missing!")
    print("Files found:", gz_files)
    sys.exit(1)